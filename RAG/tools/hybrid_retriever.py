"""
Hybrid Retriever - æ··åˆæ£€ç´¢å™¨
ç»“åˆå‘é‡æ£€ç´¢å’Œå›¾æ•°æ®åº“æŸ¥è¯¢ï¼Œæä¾›æ›´å‡†ç¡®çš„ç»“æœ

Author: EV PM DSS Team
Date: 2026-02-15
"""

from typing import List, Dict, Optional
from RAG.tools.vector_tool import VectorRetriever, format_ugc_context
from RAG.tools.graph_tool import GraphRetriever, format_ipa_scores


class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨ - å‘é‡ + å›¾è°±"""
    
    def __init__(self):
        self.vector = VectorRetriever()
        self.graph = GraphRetriever()
    
    def retrieve_for_user_insights(self, query: str) -> Dict:
        """
        ç”¨æˆ·æ´å¯Ÿä¸“ç”¨æ£€ç´¢
        
        ç­–ç•¥:
        1. ä»å›¾æ•°æ®åº“è·å–æ‰€æœ‰ Persona èŠ‚ç‚¹ï¼ˆæƒå¨æ•°æ®æºï¼‰
        2. åˆ†å±‚æ£€ç´¢ç›¸å…³ UGC è¯„è®ºï¼ˆè´¨é‡è‡ªåŠ¨æŠŠæ§ï¼‰
        3. ç»“åˆ Persona çš„ä¼˜å…ˆç»´åº¦
        
        Returns:
            Dict with personas, ugc_result, context
        """
        # 1. ä»å›¾æ•°æ®åº“è·å–æ‰€æœ‰ç”¨æˆ·ç”»åƒï¼ˆæƒå¨æ•°æ®ï¼‰
        print("=== å¼€å§‹æ£€ç´¢ç”¨æˆ·ç”»åƒ ===")
        personas = self.graph.get_all_personas()
        print(f"=== æ£€ç´¢åˆ° {len(personas)} ä¸ªç”¨æˆ·ç”»åƒ ===")
        
        # 2. åˆ†å±‚æ£€ç´¢ç›¸å…³è¯„è®ºï¼ˆè‡ªåŠ¨è´¨é‡æŠŠæ§ï¼‰
        ugc_result = self.layered_retrieve_ugc(query)
        ugc_docs = ugc_result["docs"]
        print(f"=== æ£€ç´¢åˆ° {len(ugc_docs)} æ¡è¯„è®ºï¼ˆLayer {ugc_result['layer']}ï¼Œè´¨é‡ {ugc_result['quality']:.0%}ï¼‰===")
        
        # 3. æ„å»ºä¸Šä¸‹æ–‡
        context = self._build_persona_context(personas, ugc_docs)
        
        return {
            "personas": personas,
            "ugc_reviews": ugc_docs,
            "ugc_result": ugc_result,
            "context": context,
            "retrieval_strategy": "Hybrid: Graph Personas + Vector UGC (Layered)"
        }
    
    def layered_retrieve_ugc(self, query: str, min_quality: float = 0.4, llm_client=None) -> Dict:
        """
        åˆ†å±‚æ£€ç´¢ï¼šä»å°‘åˆ°å¤šï¼ŒåŸºäºå‘é‡è·ç¦»å¿«é€Ÿåˆ¤æ–­æ˜¯å¦éœ€è¦æ‰©å¤§èŒƒå›´ï¼Œ
        æœ€ç»ˆç”¨ LLM è¯„ä¼°æ£€ç´¢è´¨é‡ï¼ˆä»…åå°æ—¥å¿—ï¼Œä¸æš´éœ²ç»™å‰ç«¯ï¼‰ã€‚
        
        ç­–ç•¥ï¼š
        - Layer 1: æ£€ç´¢ 15 æ¡ï¼Œè·ç¦»è¾¾æ ‡ç›´æ¥è¿”å›
        - Layer 2: æ‰©å¤§åˆ° 50 æ¡
        - Layer 3: æ‰©å¤§åˆ° 100 æ¡
        - ç¡®å®šæœ€ç»ˆå±‚åï¼ŒLLM è¯„ä¼°ä¸€æ¬¡è´¨é‡ï¼ˆæ‰“æ—¥å¿—ï¼‰
        
        Args:
            query: æŸ¥è¯¢é—®é¢˜
            min_quality: è·ç¦»åˆ¤æ–­çš„æœ€å°è´¨é‡é˜ˆå€¼ï¼ˆé»˜è®¤ 0.4ï¼‰
            llm_client: LLM å®¢æˆ·ç«¯ï¼ˆç”¨äºæœ€ç»ˆè´¨é‡è¯„ä¼°æ—¥å¿—ï¼‰
        
        Returns:
            {
                "docs": List[Dict],
                "quality": float,         # è·ç¦»è´¨é‡åˆ†æ•° 0~1
                "avg_distance": float,    # top-k å¹³å‡è·ç¦»
                "quality_result": Dict,   # è¯¦ç»†è´¨é‡ä¿¡æ¯
                "layer": int,
                "n_results": int,
                "warning": Optional[str]
            }
        """
        layers = [
            {"n_results": 15, "name": "å¿«é€Ÿæ£€ç´¢"},
            {"n_results": 50, "name": "æ ‡å‡†æ£€ç´¢"},
            {"n_results": 100, "name": "æ·±åº¦æ£€ç´¢"}
        ]
        
        print(f"\nğŸ” [åˆ†å±‚æ£€ç´¢] å¼€å§‹")
        
        final_docs = []
        final_layer = 1
        final_quality = 0.0
        final_avg_distance = 1.5
        final_quality_result = {}
        
        for i, layer in enumerate(layers, 1):
            n = layer["n_results"]
            print(f"\n   Layer {i}: {layer['name']}ï¼ˆ{n} æ¡ï¼‰...")
            
            docs = self.vector.search_ugc_reviews(query, n_results=n)
            
            if not docs:
                print(f"   âš ï¸ æœªæ£€ç´¢åˆ°ä»»ä½•æ–‡æ¡£")
                continue
            
            # åŸºäºå‘é‡è·ç¦»å¿«é€Ÿè®¡ç®—è´¨é‡åˆ†æ•°
            distances = [doc.get('distance', 1.0) for doc in docs]
            avg_distance = sum(distances) / len(distances)
            min_distance = min(distances)
            
            # ç»Ÿè®¡å„ç›¸å…³åº¦åŒºé—´çš„æ–‡æ¡£æ•°
            high_relevant = sum(1 for d in distances if d < 0.5)
            mid_relevant = sum(1 for d in distances if 0.5 <= d < 1.0)
            low_relevant = sum(1 for d in distances if d >= 1.0)
            
            # ç”¨ top-k å¹³å‡è·ç¦»è®¡ç®—è´¨é‡ï¼ˆä¸è¢«æ€»æ£€ç´¢é‡ç¨€é‡Šï¼‰
            top_k = min(10, len(distances))
            top_distances = sorted(distances)[:top_k]
            top_avg_distance = sum(top_distances) / len(top_distances)
            
            # å½’ä¸€åŒ–ï¼šdistance=0 â†’ quality=1, distanceâ‰¥1.5 â†’ quality=0
            quality = max(0.0, min(1.0, 1.0 - top_avg_distance / 1.5))
            
            print(f"   Top-{top_k} å¹³å‡è·ç¦»: {top_avg_distance:.3f}, è´¨é‡åˆ†æ•°: {quality:.0%}")
            print(f"   åˆ†å¸ƒ: é«˜ç›¸å…³={high_relevant}, ä¸­ç›¸å…³={mid_relevant}, ä½ç›¸å…³={low_relevant}")
            
            quality_result = {
                "is_sufficient": quality >= min_quality,
                "relevant_count": high_relevant + mid_relevant,
                "total_count": len(docs),
                "relevance_ratio": quality,
                "avg_distance": avg_distance,
                "top_avg_distance": top_avg_distance,
                "min_distance": min_distance,
                "distribution": {"high": high_relevant, "mid": mid_relevant, "low": low_relevant}
            }
            
            final_docs = docs
            final_layer = i
            final_quality = quality
            final_avg_distance = top_avg_distance
            final_quality_result = quality_result
            
            # å¦‚æœè·ç¦»è´¨é‡è¾¾æ ‡ï¼Œåœæ­¢æ‰©å¤§
            if quality >= min_quality:
                print(f"   âœ… è·ç¦»è´¨é‡è¾¾æ ‡ï¼Œä½¿ç”¨ Layer {i}")
                break
        
        if not final_docs:
            print(f"   âš ï¸ æ‰€æœ‰å±‚çº§å‡æœªæ£€ç´¢åˆ°æ–‡æ¡£")
            return {
                "docs": [], "quality": 0.0, "avg_distance": 1.5,
                "quality_result": {"is_sufficient": False, "relevant_count": 0, "total_count": 0, "relevance_ratio": 0.0},
                "layer": len(layers), "n_results": 0, "warning": None
            }
        
        print(f"   âœ… æœ€ç»ˆä½¿ç”¨ Layer {final_layer}ï¼Œå…± {len(final_docs)} æ¡æ–‡æ¡£\n")
        
        # ==================== LLM è´¨é‡è¯„ä¼°ï¼ˆä»…åå°æ—¥å¿—ï¼‰ ====================
        self._log_quality_with_llm(query, final_docs, llm_client)
        
        return {
            "docs": final_docs,
            "quality": final_quality,
            "avg_distance": final_avg_distance,
            "quality_result": final_quality_result,
            "layer": final_layer,
            "n_results": len(final_docs),
            "warning": None  # ä¸å†å‘å‰ç«¯ä¼ é€’è­¦å‘Š
        }
    
    def _log_quality_with_llm(self, query: str, docs: List[Dict], llm_client=None):
        """
        ç”¨ LLM è¯„ä¼°æ£€ç´¢è´¨é‡ï¼Œä»…æ‰“å°åˆ°åå°æ—¥å¿—ï¼Œä¸å½±å“å‰ç«¯ã€‚
        è¯„ä¼°æ„å›¾åŒ¹é…åº¦è€Œéçº¯è¯­ä¹‰è·ç¦»ã€‚
        """
        if llm_client is None:
            try:
                from RAG.config import get_siliconflow_client
                llm_client = get_siliconflow_client()
            except Exception:
                print("   âš ï¸ [LLMè´¨é‡è¯„ä¼°] æ— æ³•è·å– LLM å®¢æˆ·ç«¯ï¼Œè·³è¿‡")
                return
        
        # å–å‰ 10 æ¡æ–‡æ¡£çš„æ‘˜è¦
        docs_preview = "\n".join([
            f"æ–‡æ¡£{i+1}: {doc.get('text', '')[:150]}..."
            for i, doc in enumerate(docs[:10])
        ])
        
        prompt = f"""è¯„ä¼°ä»¥ä¸‹æ£€ç´¢ç»“æœå¯¹å›ç­”ç”¨æˆ·é—®é¢˜çš„å¸®åŠ©ç¨‹åº¦ã€‚

ç”¨æˆ·é—®é¢˜: {query}

æ£€ç´¢åˆ°çš„æ–‡æ¡£:
{docs_preview}

è¿”å› JSON:
{{
    "score": 0-10,
    "useful_count": 0-10,
    "reason": "ç®€çŸ­è¯´æ˜"
}}

è¯„åˆ†æ ‡å‡†:
- 9-10: æ–‡æ¡£é«˜åº¦ç›¸å…³ï¼Œå¯ä»¥ç›´æ¥å›ç­”é—®é¢˜
- 6-8: å¤§éƒ¨åˆ†æ–‡æ¡£æœ‰ç”¨ï¼Œèƒ½è¾…åŠ©å›ç­”
- 3-5: éƒ¨åˆ†ç›¸å…³ï¼Œéœ€è¦è¡¥å……å…¶ä»–æ•°æ®æº
- 0-2: å‡ ä¹æ— å…³ï¼Œæ— æ³•å›ç­”é—®é¢˜

åªè¿”å› JSONã€‚"""
        
        try:
            response = llm_client.chat(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=150,
                response_format={"type": "json_object"}
            )
            
            import json
            result = json.loads(response.choices[0].message.content)
            score = result.get("score", 0)
            useful = result.get("useful_count", 0)
            reason = result.get("reason", "")
            
            # åªæ‰“æ—¥å¿—
            emoji = "âœ…" if score >= 6 else "âš ï¸" if score >= 3 else "âŒ"
            print(f"\nğŸ“‹ [LLMè´¨é‡è¯„ä¼°] {emoji} è¯„åˆ†: {score}/10 | æœ‰ç”¨æ–‡æ¡£: {useful}/10 | {reason}")
            
        except Exception as e:
            print(f"\nğŸ“‹ [LLMè´¨é‡è¯„ä¼°] âš ï¸ è¯„ä¼°å¤±è´¥: {e}")
    
    def retrieve_for_competitor_analysis(self, query: str, brands: Optional[List[str]] = None) -> Dict:
        """
        ç«å“åˆ†æä¸“ç”¨æ£€ç´¢
        
        ç­–ç•¥:
        1. ä»å›¾æ•°æ®åº“è·å–è½¦å‹å‚æ•°ï¼ˆç»“æ„åŒ–å¯¹æ¯”ï¼‰- ä»…å½“æŒ‡å®šå“ç‰Œæ—¶
        2. åˆ†å±‚æ£€ç´¢ç›¸å…³ UGC è¯„è®ºï¼ˆè´¨é‡è‡ªåŠ¨æŠŠæ§ï¼‰
        3. å‘é‡æ£€ç´¢è§„æ ¼æ–‡æ¡£
        
        Returns:
            Dict with vehicles, ugc_result, spec_docs, context
        """
        print(f"\n{'='*60}")
        print(f"ğŸ” [ç«å“åˆ†ææ£€ç´¢] å¼€å§‹...")
        print(f"   ç”¨æˆ·æŸ¥è¯¢: {query}")
        print(f"   æå–çš„å“ç‰Œ: {brands}")
        print(f"{'='*60}")
        
        # 1. å›¾æ•°æ®åº“æŸ¥è¯¢è½¦å‹ï¼ˆä»…å½“æŒ‡å®šå“ç‰Œæ—¶ï¼‰
        vehicles = []
        
        if brands:
            print(f"\nğŸ“Š [å›¾è°±æ£€ç´¢] æ£€æµ‹åˆ° {len(brands)} ä¸ªå“ç‰Œï¼Œå¼€å§‹æŸ¥è¯¢è½¦å‹å‚æ•°...")
            for brand in brands:
                print(f"   æŸ¥è¯¢å“ç‰Œ: {brand}")
                vehicle_list = self.graph.get_vehicle_by_filters(brand=brand, limit=5)
                vehicles.extend(vehicle_list)
            print(f"   âœ… å›¾è°±æ£€ç´¢å®Œæˆ: å…± {len(vehicles)} ä¸ªè½¦å‹")
        else:
            print(f"\nâš ï¸ [å›¾è°±æ£€ç´¢] æœªæå–åˆ°å“ç‰Œï¼Œè·³è¿‡å›¾æ•°æ®åº“æŸ¥è¯¢")
        
        # 2. åˆ†å±‚æ£€ç´¢è¯„è®ºï¼ˆè´¨é‡è‡ªåŠ¨æŠŠæ§ï¼‰
        print(f"\nğŸ” [å‘é‡æ£€ç´¢] å¼€å§‹åˆ†å±‚æ£€ç´¢è¯„è®º...")
        ugc_result = self.layered_retrieve_ugc(query)
        ugc_docs = ugc_result["docs"]
        
        # 3. å‘é‡æ£€ç´¢è§„æ ¼æ–‡æ¡£
        spec_docs = self.vector.search_vehicle_specs(query, n_results=10)
        print(f"   âœ… å‘é‡æ£€ç´¢å®Œæˆ: {len(ugc_docs)} æ¡è¯„è®º (Layer {ugc_result['layer']}), {len(spec_docs)} ä¸ªè§„æ ¼æ–‡æ¡£")
        
        # 4. æ„å»ºä¸Šä¸‹æ–‡
        context = self._build_competitor_context(vehicles, ugc_docs, spec_docs)
        
        print(f"\n{'='*60}")
        print(f"âœ… [ç«å“åˆ†ææ£€ç´¢] å®Œæˆ")
        print(f"   è½¦å‹å‚æ•°: {len(vehicles)} ä¸ª")
        print(f"   ç”¨æˆ·è¯„è®º: {len(ugc_docs)} æ¡ï¼ˆè´¨é‡ {ugc_result['quality']:.0%}ï¼‰")
        print(f"   è§„æ ¼æ–‡æ¡£: {len(spec_docs)} ä¸ª")
        print(f"{'='*60}\n")
        
        return {
            "vehicles": vehicles,
            "ugc_reviews": ugc_docs,
            "ugc_result": ugc_result,
            "spec_docs": spec_docs,
            "context": context,
            "retrieval_strategy": "Hybrid: Graph Vehicles + Vector UGC/Specs (Layered)" if vehicles else "Vector Only: UGC/Specs (Layered)"
        }
    
    def retrieve_for_prd(self, query: str, brands: Optional[List[str]] = None) -> Dict:
        """
        PRD æ’°å†™ä¸“ç”¨æ£€ç´¢
        
        ç­–ç•¥:
        1. è·å–ç›¸å…³ Personaï¼ˆç›®æ ‡ç”¨æˆ·ï¼‰
        2. è·å–ç«å“å‚æ•°ï¼ˆä»…å½“æŒ‡å®šå“ç‰Œï¼‰
        3. åˆ†å±‚æ£€ç´¢ç›¸å…³è¯„è®ºï¼ˆéœ€æ±‚æ´å¯Ÿï¼Œè´¨é‡è‡ªåŠ¨æŠŠæ§ï¼‰
        
        Returns:
            Dict with all relevant data
        """
        print(f"\n{'='*60}")
        print(f"ğŸ“ [PRD æ£€ç´¢] å¼€å§‹...")
        print(f"   ç”¨æˆ·æŸ¥è¯¢: {query}")
        print(f"   æå–çš„å“ç‰Œ: {brands}")
        print(f"{'='*60}")
        
        # 1. è·å–ç”¨æˆ·ç”»åƒ
        print(f"\nğŸ“Š [å›¾è°±æ£€ç´¢] å¼€å§‹æ£€ç´¢ç”¨æˆ·ç”»åƒ...")
        personas = self.graph.get_all_personas()
        print(f"   âœ… ç”¨æˆ·ç”»åƒæ£€ç´¢å®Œæˆ: {len(personas)} ä¸ª")
        
        # 2. è·å–è½¦å‹æ•°æ®ï¼ˆä»…å½“æŒ‡å®šå“ç‰Œæ—¶ï¼‰
        vehicles = []
        if brands:
            print(f"\nğŸ“Š [å›¾è°±æ£€ç´¢] æ£€æµ‹åˆ° {len(brands)} ä¸ªå“ç‰Œï¼Œå¼€å§‹æŸ¥è¯¢è½¦å‹...")
            for brand in brands:
                vehicle_list = self.graph.get_vehicle_by_filters(brand=brand, limit=5)
                vehicles.extend(vehicle_list)
            print(f"   âœ… è½¦å‹æ£€ç´¢å®Œæˆ: {len(vehicles)} ä¸ª")
        else:
            print(f"\nâš ï¸ [å›¾è°±æ£€ç´¢] æœªæå–åˆ°å“ç‰Œï¼Œè·³è¿‡è½¦å‹æŸ¥è¯¢")
        
        # 3. åˆ†å±‚æ£€ç´¢è¯„è®ºï¼ˆè´¨é‡è‡ªåŠ¨æŠŠæ§ï¼‰
        print(f"\nğŸ” [å‘é‡æ£€ç´¢] å¼€å§‹åˆ†å±‚æ£€ç´¢è¯„è®ºå’Œè§„æ ¼...")
        ugc_result = self.layered_retrieve_ugc(query)
        ugc_docs = ugc_result["docs"]
        
        # 4. å‘é‡æ£€ç´¢è§„æ ¼
        spec_docs = self.vector.search_vehicle_specs(query, n_results=15)
        print(f"   âœ… å‘é‡æ£€ç´¢å®Œæˆ: {len(ugc_docs)} æ¡è¯„è®º (Layer {ugc_result['layer']}), {len(spec_docs)} ä¸ªè§„æ ¼")
        
        context = self._build_prd_context(personas, ugc_docs, spec_docs)
        
        print(f"\n{'='*60}")
        print(f"âœ… [PRD æ£€ç´¢] å®Œæˆ")
        print(f"   ç”¨æˆ·ç”»åƒ: {len(personas)} ä¸ª")
        print(f"   è½¦å‹å‚æ•°: {len(vehicles)} ä¸ª")
        print(f"   ç”¨æˆ·è¯„è®º: {len(ugc_docs)} æ¡ï¼ˆè´¨é‡ {ugc_result['quality']:.0%}ï¼‰")
        print(f"   è§„æ ¼æ–‡æ¡£: {len(spec_docs)} ä¸ª")
        print(f"{'='*60}\n")
        
        return {
            "personas": personas,
            "vehicles": vehicles,
            "ugc_reviews": ugc_docs,
            "ugc_result": ugc_result,
            "spec_docs": spec_docs,
            "context": context,
            "retrieval_strategy": "Hybrid: Full Stack (Graph + Vector, Layered)"
        }
    
    # ==================== Context Builders ====================
    def _build_persona_context(self, personas: List[Dict], ugc_docs: List[Dict]) -> str:
        """æ„å»ºç”¨æˆ·æ´å¯Ÿä¸Šä¸‹æ–‡"""
        context_parts = []
        
        # Part 1: æƒå¨çš„ç”¨æˆ·ç”»åƒæ•°æ®ï¼ˆæ˜ç¡®æ ‡æ³¨ï¼‰
        context_parts.append("=== ğŸ“Š æƒå¨ç”¨æˆ·ç”»åƒæ•°æ®ï¼ˆæ¥è‡ªçŸ¥è¯†å›¾è°±ï¼Œå‡†ç¡®å¯ä¿¡ï¼‰ ===\n")
        context_parts.append("**é‡è¦è¯´æ˜**: ä»¥ä¸‹ç”¨æˆ·ç”»åƒæ•°æ®æ¥è‡ªç»è¿‡éªŒè¯çš„çŸ¥è¯†å›¾è°±ï¼Œæ˜¯æƒå¨æ•°æ®æºã€‚\n\n")
        for i, p in enumerate(personas, 1):
            context_parts.append(f"""
**[ç”»åƒ {i}]: {p.get('persona_name', 'Unknown')}** [æƒå¨æ¥æº]
- æè¿°: {p.get('description', 'N/A')}
- è¯„è®ºæ•°: {p.get('review_count', 0)}
- ä¼˜å…ˆç»´åº¦: {', '.join([d['dimension'] for d in p.get('top_dimensions', [])])}
""")
        
        # Part 2: ç›¸å…³è¯„è®ºï¼ˆæ˜ç¡®æ ‡æ³¨ä¸ºå‚è€ƒï¼‰
        context_parts.append("\n=== ğŸ’¬ ç”¨æˆ·è¯„è®ºï¼ˆä»…ä¾›å‚è€ƒï¼Œå¯èƒ½å­˜åœ¨ä¸»è§‚æ€§å’Œåè§ï¼‰ ===\n")
        context_parts.append("**é‡è¦è¯´æ˜**: ä»¥ä¸‹æ˜¯ç”¨æˆ·ä¸ªäººè¯„è®ºï¼Œä»…ä½œä¸ºè¾…åŠ©å‚è€ƒï¼Œè¯·ç»“åˆæƒå¨ç”»åƒæ•°æ®åˆ†æã€‚\n\n")
        context_parts.append(format_ugc_context(ugc_docs, max_docs=15))  # æ˜¾ç¤ºæ›´å¤šè¯„è®º
        
        return "\n".join(context_parts)
    
    def _build_competitor_context(self, vehicles: List[Dict], ugc_docs: List[Dict], spec_docs: List[Dict]) -> str:
        """æ„å»ºç«å“åˆ†æä¸Šä¸‹æ–‡"""
        context_parts = []
        
        # Part 1: è½¦å‹å‚æ•°ï¼ˆå¦‚æœ‰ï¼‰
        if vehicles:
            context_parts.append("=== è½¦å‹å‚æ•°å¯¹æ¯”ï¼ˆæ¥è‡ªçŸ¥è¯†å›¾è°±ï¼‰===\n")
            for v in vehicles[:5]:
                context_parts.append(f"""
**{v.get('brand')} {v.get('series')} {v.get('model')}**
- ä»·æ ¼: {v.get('price', 'N/A')} ä¸‡
- ç»­èˆª: {v.get('range_cltc', 'N/A')} km
- åŠ é€Ÿ: {v.get('acceleration', 'N/A')} s
- åº§ä½: {v.get('seats', 'N/A')}
""")
        
        # Part 2: ç”¨æˆ·è¯„è®º
        context_parts.append("\n=== ç”¨æˆ·è¯„è®º ===\n")
        context_parts.append(format_ugc_context(ugc_docs, max_docs=15))  # æ˜¾ç¤ºæ›´å¤šè¯„è®º
        
        return "\n".join(context_parts)
    
    def _build_prd_context(self, personas: List[Dict], ugc_docs: List[Dict], spec_docs: List[Dict]) -> str:
        """æ„å»º PRD ä¸Šä¸‹æ–‡"""
        context_parts = []
        
        context_parts.append("=== ğŸ“Š ç›®æ ‡ç”¨æˆ·ç”»åƒï¼ˆæƒå¨æ•°æ®ï¼‰ ===\n")
        context_parts.append("**æ•°æ®æ¥æº**: ç»è¿‡éªŒè¯çš„çŸ¥è¯†å›¾è°±\n\n")
        for p in personas[:3]:
            context_parts.append(f"- **[ç”»åƒ]** {p.get('persona_name')}: {p.get('description')}\n")
        
        context_parts.append("\n=== ğŸ’¬ ç”¨æˆ·éœ€æ±‚æ´å¯Ÿï¼ˆåŸºäºçœŸå®è¯„è®ºï¼‰ ===\n")
        context_parts.append("**æ•°æ®æ¥æº**: ç”¨æˆ·è¯„è®ºï¼ˆä»…ä¾›å‚è€ƒï¼‰\n\n")
        context_parts.append(format_ugc_context(ugc_docs, max_docs=20))  # PRDéœ€è¦æ›´å¤šæ•°æ®
        
        return "\n".join(context_parts)
